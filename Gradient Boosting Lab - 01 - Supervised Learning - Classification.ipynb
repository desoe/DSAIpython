{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af413ab9",
   "metadata": {},
   "source": [
    "Modify the Gradient Boosting scratch code in our lecture such that:\n",
    "- Notice that we are still using max_depth = 1.  Attempt to tweak min_samples_split, max_depth for the regression and see whether we can achieve better mse on our boston data\n",
    "- Notice that we only write scratch code for gradient boosting for regression, add some code so that it also works for binary classification.  Load the breast cancer data from sklearn and see that it works.\n",
    "- Further change the code so that it works for multiclass classification.  Load the digits data from sklearn and see that it works\n",
    "- Put everything into class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25fbd44",
   "metadata": {},
   "source": [
    "#### st122645"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "c51cdf67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.dummy import DummyRegressor, DummyClassifier\n",
    "from sklearn.datasets import  load_boston, load_breast_cancer, load_digits\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "class GradientBoosting:\n",
    "    def __init__(self, S= 200, learning_rate=1, max_depth= 1, min_samples_split=2, regression= True ):\n",
    "        self.S = S\n",
    "        self.learning_rate= learning_rate\n",
    "        self.tree_params = { \"max_depth\": max_depth, \"min_samples_split\": min_samples_split}\n",
    "        self.models = [DecisionTreeRegressor(**self.tree_params) for _ in range(S)]\n",
    "        self.regression = regression\n",
    "        if regression == True:\n",
    "            first_model = DummyRegressor(strategy='mean')\n",
    "#             self.models.insert(0, DummyRegressor(strategy=\"mean\") )\n",
    "            \n",
    "        else:\n",
    "            first_model = DummyClassifier(strategy='most_frequent')\n",
    "#             self.models.insert(0, DummyClassifier(strategy=\"most_frequent\"))\n",
    "            \n",
    "        self.models.insert(0, first_model)\n",
    "\n",
    "    \n",
    "    def grad(self,y, h):\n",
    "        return y - h\n",
    "\n",
    "    def softmax(self, yhat):\n",
    "        return np.exp(yhat) / np.expand_dims(np.sum(np.exp(yhat), axis=1), axis=1)\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.models[0].fit(X,y)\n",
    "        for i in range(self.S):\n",
    "            y_pred = self.predict(X, self.models[:i+1], with_argmax=False)\n",
    "            residual = self.grad(y, y_pred)\n",
    "            self.models[i+1].fit(X, residual)\n",
    "        \n",
    "    def predict(self,X, models= None, with_argmax=True):\n",
    "        if models is None:\n",
    "            models = self.models\n",
    "        h0 = models[0].predict(X)\n",
    "        boosting = sum(self.learning_rate * model.predict(X) for model in models[1:])\n",
    "        yhat = h0 + boosting\n",
    "        if not self.regression:\n",
    "            yhat = np.exp(yhat) / np.sum(np.exp(yhat), axis=1, keepdims=True)\n",
    "            if with_argmax:\n",
    "                yhat = np.argmax(yhat, axis=1)\n",
    "        return yhat\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "eea327ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CP dsai MSE:  12.92985577558652\n",
      "Sklearn MSE:  8.032644175128802\n"
     ]
    }
   ],
   "source": [
    "# Regression - Boston Dataset\n",
    "\n",
    "X, y = load_boston(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "clf = GradientBoosting();\n",
    "clf.fit(X_train,y_train)\n",
    "yhat = clf.predict(X_test)\n",
    "\n",
    "print(\"CP dsai MSE: \", mean_squared_error(y_test, yhat))\n",
    "\n",
    "\n",
    "n_estimators = 200\n",
    "sklearn_model = GradientBoostingRegressor(n_estimators=n_estimators, learning_rate = 0.1,\n",
    "                                            max_depth=3,loss='ls')\n",
    "\n",
    "yhat_sk = sklearn_model.fit(X_train, y_train).predict(X_test)\n",
    "print(\"Sklearn MSE: \", mean_squared_error(y_test, yhat_sk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "5220e020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CP dsai MSE:  0.04093567251461988\n",
      "CP dsai Accuracy Score:  0.9590643274853801\n",
      "Sklearn MSE:  0.03508771929824561\n",
      "Sklearn accuracy:  0.9649122807017544\n"
     ]
    }
   ],
   "source": [
    "# Binary - Cancer Dataset\n",
    "\n",
    "X, y = load_breast_cancer(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "y_train_encoded = np.zeros((y_train.shape[0], len(set(y))))\n",
    "# print(y_train_encoded)\n",
    "for each_class in range(len(set(y))):\n",
    "    cond = y_train==each_class\n",
    "    y_train_encoded[np.where(cond), each_class] = 1\n",
    "\n",
    "clf = GradientBoosting(regression=False);\n",
    "clf.fit(X_train,y_train_encoded)\n",
    "yhat = clf.predict(X_test)\n",
    "\n",
    "print(\"CP dsai MSE: \", mean_squared_error(y_test, yhat))\n",
    "print(\"CP dsai Accuracy Score: \", accuracy_score(y_test, yhat))\n",
    "\n",
    "\n",
    "sklearn_model = GradientBoostingClassifier(n_estimators=n_estimators,learning_rate = 0.1,max_depth=1)\n",
    "\n",
    "yhat_sk = sklearn_model.fit(X_train, y_train).predict(X_test)\n",
    "print(\"Sklearn MSE: \", mean_squared_error(y_test, yhat_sk))\n",
    "print(\"Sklearn accuracy: \", accuracy_score(y_test, yhat_sk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "0421323e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CP dsai MSE:  1.3351851851851853\n",
      "CP dsai Accuracy Score:  0.924074074074074\n",
      "Sklearn MSE:  0.8574074074074074\n",
      "Sklearn accuracy:  0.9481481481481482\n"
     ]
    }
   ],
   "source": [
    "# Multiclass - Digit Dataset\n",
    "\n",
    "X, y = load_digits(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "y_train_encoded = np.zeros((y_train.shape[0], len(set(y))))\n",
    "for each_class in range(len(set(y))):\n",
    "    cond = y_train==each_class\n",
    "    y_train_encoded[np.where(cond), each_class] = 1\n",
    "\n",
    "clf = GradientBoosting(regression=False);\n",
    "\n",
    "clf.fit(X_train,y_train_encoded)\n",
    "\n",
    "yhat = clf.predict(X_test)\n",
    "\n",
    "print(\"CP dsai MSE: \", mean_squared_error(y_test, yhat))\n",
    "print(\"CP dsai Accuracy Score: \", accuracy_score(y_test, yhat))\n",
    "\n",
    "\n",
    "sklearn_model = GradientBoostingClassifier(n_estimators=n_estimators,learning_rate = 0.1,max_depth=1)\n",
    "\n",
    "yhat_sk = sklearn_model.fit(X_train, y_train).predict(X_test)\n",
    "print(\"Sklearn MSE: \", mean_squared_error(y_test, yhat_sk))\n",
    "print(\"Sklearn accuracy: \", accuracy_score(y_test, yhat_sk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b985c655",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pythonDSAI",
   "language": "python",
   "name": "pythondsai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
